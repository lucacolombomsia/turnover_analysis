{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_for_sklearn(data):\n",
    "    data.columns = map(str.lower, data.columns)\n",
    "    data.sales = data.sales.str.lower()\n",
    "    # create dummies for categorical variables\n",
    "    data = data.join(pd.get_dummies(data[\"sales\"], prefix=\"dept\"))\n",
    "    data = data.join(pd.get_dummies(data[\"salary\"], prefix=\"salary\"))\n",
    "    # drop variables that should not be in the X matrix\n",
    "    # these include: employer ID, categorical variables that have\n",
    "    # been converted into dummies and one dummy per each\n",
    "    # categorical variable (to avoid perfect multicollinearity)\n",
    "    data = data.drop([\"emp_id\", \"salary_high\", \"dept_accounting\",\n",
    "                      \"sales\", \"salary\"], axis=1)\n",
    "    # the test data has an extra column compared to the train data\n",
    "    # it's the name of the employee and it has to be dropped\n",
    "    try:\n",
    "        data = data.drop([\"name\"], axis=1)\n",
    "    except ValueError:\n",
    "        pass\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13999, 11)\n",
      "(500, 11)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('../Data/train.csv')\n",
    "print(data.shape)\n",
    "test = pd.read_csv('../Data/test.csv')\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13999, 18)\n",
      "(500, 18)\n"
     ]
    }
   ],
   "source": [
    "X = preprocess_for_sklearn(data.drop([\"left\"], axis=1))\n",
    "y = data.left\n",
    "print(X.shape)\n",
    "Xpred = preprocess_for_sklearn(test.drop([\"left\"], axis=1))\n",
    "ypred = test.left\n",
    "print(Xpred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.988\n",
      "Recall: 0.9512195121951219\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[377,   0],\n",
       "       [  6, 117]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=15, random_state=45, n_estimators=200)\n",
    "clf.fit(X, y)\n",
    "\n",
    "predicted_labels = clf.predict(Xpred)\n",
    "\n",
    "print(\"Accuracy: \" + str(accuracy_score(ypred, predicted_labels)))\n",
    "print(\"Recall: \" + str(recall_score(ypred, predicted_labels)))\n",
    "\n",
    "confusion_matrix(ypred, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['satisfaction_level', 'last_evaluation', 'number_project', 'average_montly_hours', 'time_spend_company', 'work_accident', 'promotion_last_5years', 'dept_hr', 'dept_it', 'dept_management', 'dept_marketing', 'dept_product_mng', 'dept_randd', 'dept_sales', 'dept_support', 'dept_technical', 'salary_low', 'salary_medium']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.31486599, 0.1165723 , 0.18519465, 0.15299445, 0.19243088,\n",
       "       0.00913026, 0.00162846, 0.00120084, 0.00145694, 0.00146177,\n",
       "       0.00092767, 0.00087791, 0.00151864, 0.00278334, 0.00241922,\n",
       "       0.00306884, 0.00810917, 0.00335868])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(list(X))\n",
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.008100544128256499,\n",
       " 0.023456534627407516,\n",
       " 0.9990197344218668,\n",
       " 0.021045376238137438,\n",
       " 0.006014165637143473,\n",
       " 0.002130667846515974,\n",
       " 0.0008978126829792089,\n",
       " 0.0019089629366426002,\n",
       " 0.9649690280833286,\n",
       " 0.38003538030481493,\n",
       " 0.9975055706352188,\n",
       " 0.002083905385869403,\n",
       " 0.032414388168441305,\n",
       " 0.9998491379310345,\n",
       " 0.011446800094212794,\n",
       " 0.02057253564281204,\n",
       " 0.0009451900407798677,\n",
       " 0.07186700308466848,\n",
       " 0.013899775990597918,\n",
       " 0.01042989417989418,\n",
       " 0.009338454768357657,\n",
       " 0.0020202919407212917,\n",
       " 0.9979705037384082,\n",
       " 0.0004467846840739008,\n",
       " 0.008599570941262567,\n",
       " 0.0008567269894048809,\n",
       " 0.0009302035262482726,\n",
       " 0.00571038067439078,\n",
       " 0.0044110465485383155,\n",
       " 0.005449235629075776,\n",
       " 0.003305273923969109,\n",
       " 0.015020851976388245,\n",
       " 0.034706108890349044,\n",
       " 0.04418514331420325,\n",
       " 0.022400884192829738,\n",
       " 0.03317453295090429,\n",
       " 0.0004982868404914277,\n",
       " 0.0018062467475153038,\n",
       " 0.028321886215422434,\n",
       " 0.9991217752381932,\n",
       " 0.00123058291136255,\n",
       " 0.10534241427722608,\n",
       " 0.0014065327832014727,\n",
       " 0.01710421863531836,\n",
       " 0.0010109902616523437,\n",
       " 0.0957842646782436,\n",
       " 0.045097005545752966,\n",
       " 0.9999328859060402,\n",
       " 0.002289953822380044,\n",
       " 0.029532748809806265,\n",
       " 0.028563951295548534,\n",
       " 1.0,\n",
       " 0.9730434782608697,\n",
       " 0.010748300286383666,\n",
       " 0.0007275674642291363,\n",
       " 0.27759861983088935,\n",
       " 0.005800149205255861,\n",
       " 0.0031808229577665087,\n",
       " 0.002708623338439981,\n",
       " 0.01241650582055851,\n",
       " 0.0009782481631255301,\n",
       " 0.0008262506173673013,\n",
       " 0.03391016857495125,\n",
       " 0.019058394299067593,\n",
       " 0.9988255247979937,\n",
       " 0.9861208756673909,\n",
       " 0.002122652856665703,\n",
       " 0.8552969105384183,\n",
       " 0.959404139466657,\n",
       " 1.0,\n",
       " 0.0017819224793082752,\n",
       " 0.1373850718384046,\n",
       " 0.07891411641943556,\n",
       " 0.004857186209544226,\n",
       " 0.014534178599329721,\n",
       " 0.00372148336478882,\n",
       " 0.005718788010351249,\n",
       " 0.00320097643421032,\n",
       " 0.9754664965300073,\n",
       " 0.9979573757632477,\n",
       " 0.000534956860723427,\n",
       " 0.0973125769578297,\n",
       " 0.9944662412754879,\n",
       " 0.997919243779945,\n",
       " 0.019094105774980448,\n",
       " 0.07205974287918998,\n",
       " 0.9663657624855958,\n",
       " 0.9974864762923482,\n",
       " 0.021118001125721785,\n",
       " 0.06571004217515948,\n",
       " 0.08693169458950693,\n",
       " 0.17525176368533202,\n",
       " 0.08981751209632483,\n",
       " 0.0011304369710124686,\n",
       " 0.0017556151046744972,\n",
       " 0.009790833243348965,\n",
       " 0.9986424932773126,\n",
       " 0.011192136601726575,\n",
       " 0.05536960127371735,\n",
       " 0.9993762327416174,\n",
       " 0.0037292117327991365,\n",
       " 0.0009733300436351838,\n",
       " 0.0014350520450683675,\n",
       " 0.0002908444260360362,\n",
       " 0.025593300870422726,\n",
       " 0.0022455997178082044,\n",
       " 0.215,\n",
       " 0.003118369316296039,\n",
       " 0.050751324401608705,\n",
       " 0.031715308313643095,\n",
       " 0.0009701357167506557,\n",
       " 0.00454058761759263,\n",
       " 0.001295421364251399,\n",
       " 0.004567261442943783,\n",
       " 0.9954896551724138,\n",
       " 0.006338936575157287,\n",
       " 0.003119655049281177,\n",
       " 0.9175672705778485,\n",
       " 0.002861481039570414,\n",
       " 0.0008679297316757964,\n",
       " 0.006337952393782696,\n",
       " 0.9654703524095076,\n",
       " 0.0030867370022052793,\n",
       " 0.025069464225893845,\n",
       " 0.7800700187554874,\n",
       " 0.9971118379996065,\n",
       " 0.000998009191054607,\n",
       " 0.00232591220943101,\n",
       " 0.0016935157780236685,\n",
       " 0.011303597912445252,\n",
       " 0.12882317628054593,\n",
       " 0.0026291697455332764,\n",
       " 0.9996420373393186,\n",
       " 0.13198148647019717,\n",
       " 0.00030197814250460995,\n",
       " 0.08409418061686134,\n",
       " 0.0002561488561339031,\n",
       " 0.3062097050923133,\n",
       " 0.028525579083208803,\n",
       " 0.0026662487080453016,\n",
       " 0.9951970302954775,\n",
       " 0.9983789564198443,\n",
       " 0.9985626274872694,\n",
       " 0.006108281554783039,\n",
       " 0.056568820990047494,\n",
       " 0.0007172154715992331,\n",
       " 0.9673827762853558,\n",
       " 0.0010302748497687667,\n",
       " 0.010493202949300808,\n",
       " 0.0019762083266424914,\n",
       " 0.003421818220577825,\n",
       " 0.998942005371056,\n",
       " 0.01044045417331686,\n",
       " 0.06173044905336583,\n",
       " 0.9407886898495903,\n",
       " 0.005530717951609935,\n",
       " 0.9968043505566204,\n",
       " 0.07775466653057565,\n",
       " 0.0004189487618653266,\n",
       " 0.001519891235906396,\n",
       " 0.9976694741143913,\n",
       " 0.0006444082038281871,\n",
       " 0.9933050623403241,\n",
       " 0.007208106121068634,\n",
       " 0.010228095156424019,\n",
       " 0.7776904477545277,\n",
       " 0.020346215504882848,\n",
       " 0.0003541350555807719,\n",
       " 0.004117855438106233,\n",
       " 0.006714167137238017,\n",
       " 0.0013736753269969722,\n",
       " 0.0011415107309397448,\n",
       " 0.01560448454870944,\n",
       " 0.026654467598207988,\n",
       " 0.005395126696456015,\n",
       " 0.994789101729589,\n",
       " 0.007460023981126286,\n",
       " 0.9987524366645414,\n",
       " 0.9790232330437546,\n",
       " 0.0008346397308709,\n",
       " 0.00015432822840209473,\n",
       " 0.010219585276507992,\n",
       " 0.9967670199731538,\n",
       " 0.0,\n",
       " 0.0062052929318180804,\n",
       " 0.0014480355523963568,\n",
       " 0.007969013457513809,\n",
       " 0.9987153420331069,\n",
       " 0.12043571360612308,\n",
       " 0.9937988419893293,\n",
       " 0.07140179932951116,\n",
       " 0.018821739118191586,\n",
       " 0.3462549047279138,\n",
       " 0.01,\n",
       " 0.0020755345393882155,\n",
       " 0.018243908572231793,\n",
       " 0.00015913528704514915,\n",
       " 0.07198545769230195,\n",
       " 0.00211574349628832,\n",
       " 0.001580358030803668,\n",
       " 0.0007116734713874603,\n",
       " 0.824392410145416,\n",
       " 0.0032410716733119425,\n",
       " 0.03554653278591811,\n",
       " 0.015305340218033245,\n",
       " 0.9708460727630347,\n",
       " 0.8617708390813698,\n",
       " 0.9693484152224786,\n",
       " 0.01084885047185023,\n",
       " 0.9985012285012285,\n",
       " 0.0056440900786314885,\n",
       " 0.595568852240883,\n",
       " 0.024717872432281598,\n",
       " 0.9983330377148526,\n",
       " 0.020377519595837678,\n",
       " 0.002576315544642117,\n",
       " 0.0004853030802925533,\n",
       " 0.9990197344218668,\n",
       " 0.009758999045775709,\n",
       " 0.003649509546863352,\n",
       " 0.000594866515598223,\n",
       " 0.0012455780959698284,\n",
       " 0.00013828238370906402,\n",
       " 0.1913430828856621,\n",
       " 0.08377268267255669,\n",
       " 0.061356708886996784,\n",
       " 0.008152351869325307,\n",
       " 0.04673538761515015,\n",
       " 0.06699424266747267,\n",
       " 0.0023409711887439704,\n",
       " 0.8296892530775554,\n",
       " 0.9547428739883004,\n",
       " 0.01304877002159849,\n",
       " 0.01721115333767173,\n",
       " 0.998792899408284,\n",
       " 0.022054032139171453,\n",
       " 0.0003297014723611826,\n",
       " 0.0006505926290468714,\n",
       " 0.9967195806124834,\n",
       " 0.9987876249942882,\n",
       " 0.011063958679069556,\n",
       " 0.9712873704615115,\n",
       " 0.9997928994082841,\n",
       " 0.018367317279153618,\n",
       " 0.003065495240002323,\n",
       " 0.026414175242772075,\n",
       " 0.003027574611541533,\n",
       " 0.006260181828617059,\n",
       " 0.08810326084891973,\n",
       " 0.0017259769447173382,\n",
       " 0.0946502642585639,\n",
       " 0.0009806795824557012,\n",
       " 0.8737884120666927,\n",
       " 0.7453231282000901,\n",
       " 0.006868621261666263,\n",
       " 0.000626990540225881,\n",
       " 0.0029524687155870898,\n",
       " 0.050643906053716756,\n",
       " 0.005072227276952172,\n",
       " 0.005857886561104551,\n",
       " 0.006312618576677286,\n",
       " 0.9985685767948909,\n",
       " 0.03350356115044253,\n",
       " 0.03478153351404235,\n",
       " 0.044165587494386135,\n",
       " 0.29607489358422984,\n",
       " 0.01388681882457667,\n",
       " 0.9998491379310345,\n",
       " 0.023385672607145757,\n",
       " 0.04970486021733176,\n",
       " 1.0,\n",
       " 0.012032894801282907,\n",
       " 0.9979731357259827,\n",
       " 0.9783580038699131,\n",
       " 0.09548209347259223,\n",
       " 0.06576235934123038,\n",
       " 1.0,\n",
       " 0.0021378861026438347,\n",
       " 0.000891946780015695,\n",
       " 0.9972231798642208,\n",
       " 0.0006046271325955319,\n",
       " 0.006442023649154105,\n",
       " 0.000772467544229683,\n",
       " 0.013209938271703367,\n",
       " 0.00598329260724877,\n",
       " 0.9987496361344554,\n",
       " 0.02975971498797526,\n",
       " 0.028680741010181237,\n",
       " 0.4795573714507881,\n",
       " 0.0070387085137085135,\n",
       " 0.0008423696584288209,\n",
       " 0.002749456510472314,\n",
       " 0.06516092437923998,\n",
       " 0.10306469919977741,\n",
       " 0.01406027342863626,\n",
       " 0.018148264211750597,\n",
       " 1.0,\n",
       " 0.0016535363453699637,\n",
       " 0.0003701732976457606,\n",
       " 0.015374580205669239,\n",
       " 0.9981642261141066,\n",
       " 0.007075848665260454,\n",
       " 0.018232659050422297,\n",
       " 0.0016896213285910228,\n",
       " 0.001650499542029868,\n",
       " 0.950565392486957,\n",
       " 0.04439617329686709,\n",
       " 0.9987455549920109,\n",
       " 0.002982329334809672,\n",
       " 0.9790609035457827,\n",
       " 0.05675923019016562,\n",
       " 1.0,\n",
       " 0.003173439873136196,\n",
       " 0.002488910620281189,\n",
       " 0.013214285714285713,\n",
       " 0.9888087163464409,\n",
       " 0.9967195806124834,\n",
       " 0.015400504296527777,\n",
       " 0.001523427545196599,\n",
       " 0.14328135028529687,\n",
       " 0.0016788053301428929,\n",
       " 0.9989876693414588,\n",
       " 0.9997928994082841,\n",
       " 0.3846097076708635,\n",
       " 0.009217383303011088,\n",
       " 0.9983620524732535,\n",
       " 0.0005713184651251681,\n",
       " 0.00037450263012414115,\n",
       " 0.0017618441739978463,\n",
       " 0.04681052349337913,\n",
       " 0.020353499047940454,\n",
       " 0.011433057563410912,\n",
       " 0.014985497515867963,\n",
       " 0.016661950984188875,\n",
       " 0.0027194454929426936,\n",
       " 0.009686201813833277,\n",
       " 0.005044752384120841,\n",
       " 0.9990833136997317,\n",
       " 0.9866959666432359,\n",
       " 0.006669035134550928,\n",
       " 0.00326248180318885,\n",
       " 0.0005915760846618895,\n",
       " 0.032089075162909236,\n",
       " 0.0007279897954000218,\n",
       " 0.017691423791525007,\n",
       " 0.05065847934505843,\n",
       " 0.019174766464415485,\n",
       " 0.0005053003159005628,\n",
       " 0.00027543367105484933,\n",
       " 0.001738613735448717,\n",
       " 0.01056814142177655,\n",
       " 0.0016907373248014606,\n",
       " 0.005140434778649613,\n",
       " 0.030746852537898516,\n",
       " 0.035997526802417336,\n",
       " 0.010115148724803388,\n",
       " 0.9640898010302884,\n",
       " 0.00734555722860058,\n",
       " 0.012187265657303777,\n",
       " 0.0012664234204472918,\n",
       " 0.9972193201961064,\n",
       " 0.9988198566400642,\n",
       " 0.020583016690175874,\n",
       " 0.9994408200821333,\n",
       " 0.0016980388090388418,\n",
       " 0.971023468212049,\n",
       " 0.004579138024446769,\n",
       " 0.9783399009672192,\n",
       " 0.0244386292351198,\n",
       " 0.0031505399522365075,\n",
       " 0.03258503710052724,\n",
       " 0.0029449588699286063,\n",
       " 0.9980324791831682,\n",
       " 0.009615704671991344,\n",
       " 0.0007171281238932867,\n",
       " 0.0068920000817993595,\n",
       " 0.9763334231406153,\n",
       " 0.001355587927652483,\n",
       " 0.05146662794553718,\n",
       " 0.03407636860853566,\n",
       " 0.005533113601352256,\n",
       " 0.020951739789141496,\n",
       " 0.42689945994436473,\n",
       " 0.010977551245607954,\n",
       " 0.04023555118882531,\n",
       " 0.9554195776390432,\n",
       " 0.016392785225053042,\n",
       " 0.9571582966255017,\n",
       " 0.025314164149373295,\n",
       " 0.027783038187378307,\n",
       " 0.0024071716355648838,\n",
       " 0.005812449354264896,\n",
       " 0.9979912712906571,\n",
       " 0.002091313026885996,\n",
       " 0.000869250280349352,\n",
       " 0.01053474861040797,\n",
       " 0.008821289536500791,\n",
       " 0.01715289863825671,\n",
       " 0.042452691273188535,\n",
       " 0.9854915623461877,\n",
       " 0.15176958108548205,\n",
       " 0.0008135139461663712,\n",
       " 0.0011873292362174397,\n",
       " 0.9578407414586194,\n",
       " 0.0012897105970540216,\n",
       " 0.0029537319020456598,\n",
       " 0.9870594475252524,\n",
       " 0.009719032847581589,\n",
       " 0.02986489397190474,\n",
       " 0.01119286284696151,\n",
       " 0.012475020753875599,\n",
       " 0.6089652557711291,\n",
       " 0.0027376202028349637,\n",
       " 0.0026072252637988403,\n",
       " 0.00803687351734446,\n",
       " 0.0024588593407970346,\n",
       " 0.007930724528996564,\n",
       " 0.007029291437232607,\n",
       " 0.0007344355726382039,\n",
       " 0.013975061170713343,\n",
       " 0.0355523285648816,\n",
       " 0.9804113893473374,\n",
       " 0.014985251772720176,\n",
       " 0.001211836783864096,\n",
       " 0.9986454286375728,\n",
       " 0.9966936459376362,\n",
       " 0.04678862358449622,\n",
       " 0.99424487088989,\n",
       " 0.9903672517974885,\n",
       " 0.07542433946083187,\n",
       " 0.9563000000000001,\n",
       " 0.01839318361671668,\n",
       " 0.9999085349279696,\n",
       " 0.00165302085914904,\n",
       " 0.006327704405687643,\n",
       " 0.016769264983714866,\n",
       " 0.003996993084210545,\n",
       " 0.0007847261210588466,\n",
       " 0.000208937881674292,\n",
       " 0.9866959666432359,\n",
       " 0.040512213319747324,\n",
       " 1.0,\n",
       " 0.014764119140500003,\n",
       " 8.047763107203867e-05,\n",
       " 0.9987848419031757,\n",
       " 0.08888528165042793,\n",
       " 0.06904636890202567,\n",
       " 0.0005201446254697453,\n",
       " 0.0012598694410901035,\n",
       " 0.002102016790307096,\n",
       " 0.0008473503010889405,\n",
       " 0.013978718300327996,\n",
       " 0.008370263988081354,\n",
       " 0.07875574887687162,\n",
       " 0.014025553745383303,\n",
       " 0.0011591111343712277,\n",
       " 0.02487185781376152,\n",
       " 0.0036805582395040455,\n",
       " 0.17141727930442344,\n",
       " 0.010582169738858185,\n",
       " 0.9979429053163112,\n",
       " 0.02194788340172325,\n",
       " 0.00404040087539562,\n",
       " 0.9865966778505024,\n",
       " 0.9980732855195745,\n",
       " 0.0001531132882194442,\n",
       " 0.0014591610257175852,\n",
       " 0.9991008369771568,\n",
       " 0.005610349295912337,\n",
       " 0.007159905811943552,\n",
       " 0.02396939177962039,\n",
       " 0.0006403794013805689,\n",
       " 0.013955683175278384,\n",
       " 0.008338233889609253,\n",
       " 0.004334187654331239,\n",
       " 0.047747007881837146,\n",
       " 0.0173267584173936,\n",
       " 0.991092119250997,\n",
       " 0.016885646814722908,\n",
       " 0.014452564004326773,\n",
       " 0.0056085637059347816,\n",
       " 0.8436620305655971,\n",
       " 0.9621609400445478,\n",
       " 0.00024511994006664353,\n",
       " 0.04016841344095906,\n",
       " 0.001097911590593932,\n",
       " 0.003709755867272006,\n",
       " 0.9948472070160654,\n",
       " 0.0023944293981979794,\n",
       " 0.0007414273319981375,\n",
       " 0.0024031032673131367,\n",
       " 0.022731923147851486,\n",
       " 0.006438746244888519,\n",
       " 0.9987524366645414,\n",
       " 0.23754000333909253,\n",
       " 0.022604068378143674,\n",
       " 0.9937839746253819,\n",
       " 0.0009550401925227362,\n",
       " 0.0004145788328874078,\n",
       " 0.0007935834379595321]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = list(clf.predict_proba(Xpred)[:, 1])\n",
    "predictions\n",
    "#0.0081, 0.0234, 0.999, 0.0210"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9987496361344554"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 285\n",
    "print(predicted_labels[n])\n",
    "pred_proba.loc[n,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9987496361344554"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_obs = np.array([Xpred.loc[285,:]])\n",
    "clf.predict_proba(test_obs)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = np.array([[0.11, 0.8, 6.0, 285.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]])\n",
    "\n",
    "#change hours, first of second row(promotion) and last two (salary)\n",
    "x = np.array([[0.21, 0.8, 6.0, 250.0, 4.0, 0.0,\n",
    " 1.0, 0.0, 0.0,\n",
    " 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.035365913818268854"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(x)[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(max_depth = 3)\n",
    "clf = clf.fit(X, y)\n",
    "\n",
    "predicted_labels = clf.predict(Xpred)\n",
    "\n",
    "print(\"Accuracy: \" + str(accuracy_score(ypred, predicted_labels)))\n",
    "print(\"Recall: \" + str(recall_score(ypred, predicted_labels)))\n",
    "\n",
    "confusion_matrix(ypred, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(X))\n",
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba = pd.DataFrame(clf.predict_proba(Xpred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 329\n",
    "print(predicted_labels[n])\n",
    "pred_proba.loc[n,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_obs = np.array([Xpred.loc[329,:]])\n",
    "clf.predict_proba(test_obs)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[0.12, 0.6, 4.0, 400.0, 5.0, 0.0,\n",
    " 0.0, 0.0, 0.0,\n",
    " 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict_proba(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters = {'max_depth': list(range(3,21))}\n",
    "#clf = grid_search.GridSearchCV(tree.DecisionTreeClassifier(), parameters, n_jobs=2, cv = 10)\n",
    "#clf.fit(X, y)\n",
    "#tree_model = clf.best_estimator_\n",
    "#print(clf.best_score_, clf.best_params_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X, y)\n",
    "\n",
    "predicted_labels = logreg.predict(Xpred)\n",
    "\n",
    "print(\"Accuracy: \" + str(accuracy_score(ypred, predicted_labels)))\n",
    "print(\"Recall: \" + str(recall_score(ypred, predicted_labels)))\n",
    "\n",
    "confusion_matrix(ypred, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playground and multiple piles of crap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(table_name):\n",
    "    engine = create_engine(config.database_config)\n",
    "    sql = \"select * from \" + table_name\n",
    "    data = pd.read_sql_query(sql, con = engine)\n",
    "    try:\n",
    "        y = data.left\n",
    "        data = data.drop([\"left\"], axis = 1)\n",
    "        return (data, y)\n",
    "    except:\n",
    "        return data\n",
    "\n",
    "def preprocess_for_sklearn(data):\n",
    "    data.columns = map(str.lower, data.columns)\n",
    "    data.sales = data.sales.str.lower()\n",
    "    #create dummies for categorical variables\n",
    "    data = data.join(pd.get_dummies(data[\"sales\"], prefix=\"dept\"))\n",
    "    data = data.join(pd.get_dummies(data[\"salary\"], prefix=\"salary\"))\n",
    "    #drop variables that should not be in the X matrix\n",
    "    #these include: left (ie the target variable), employer ID, categorical vars and\n",
    "    #one dummy per category (to avoid perfect multicollinearity)\n",
    "    data = data.drop([\"emp_id\", \"salary_high\", \"dept_accounting\", \"sales\", \"salary\"], axis = 1)\n",
    "    try:\n",
    "        data = data.drop([\"name\"], axis = 1)\n",
    "    except:\n",
    "        pass\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import math\n",
    "import pickle\n",
    "pd.options.display.max_columns = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Next block does prediction using scikitlearn, should match results below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = read_data('employees_hist_data')\n",
    "X = preprocess_for_sklearn(X)\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X, y)\n",
    "y_pred = logreg.predict(X.loc[0:1,:])\n",
    "y_pred_prob = logreg.predict_proba(X.loc[0:10,:])[:, 1]\n",
    "print(y_pred)\n",
    "print(y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(X.loc[2,:])\n",
    "test = np.array([a])\n",
    "y_pred = logreg.predict_proba(test)[:, 1][0]\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check everything worked nicely with pickle approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predict using scikitlearn on a single observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_filename = '../models/logistic.pkl'\n",
    "model_pkl = open(pkl_filename, 'rb')\n",
    "model = pickle.load(model_pkl)\n",
    "model_pkl.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(X.loc[2,:])\n",
    "a[6] = 1\n",
    "a[16] = 0\n",
    "a[17] = 0\n",
    "test = np.array([a])\n",
    "y_pred = model.predict_proba(test)[:, 1][0]\n",
    "y_pred\n",
    "#60% when low\n",
    "#46.8% when medium\n",
    "#20.8% when high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.loc[2,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Test the app with this data:\n",
    "- [0.57, 0.82, 4, 269, 2, False, False, Technical, Medium] ==> 21.30%\n",
    "- [0.97, 0.61, 4, 262, 3, True, True, Marketing, Medium] ==> 0.52%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[6] = 0\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
